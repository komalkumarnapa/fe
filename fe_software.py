# -*- coding: utf-8 -*-
"""FE software.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XwsS94KwK-g_mojF1GD6HVt3W9W_SMgR
"""

import streamlit as st
import os
import zipfile
import shutil
import tempfile
import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.models import resnet18, vgg16, mobilenet_v2
from transformers import ViTModel, ViTImageProcessor
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, chi2
from boruta import BorutaPy
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

st.title("ðŸ§  Customizable Image Classification App")

# === Sidebar Configuration ===
st.sidebar.header("Step 1: Upload Dataset")
zip_file = st.sidebar.file_uploader("Upload ZIP of image folders", type=["zip"])

st.sidebar.header("Step 2: Choose Algorithms")
feature_extractors = ["ResNet-18", "VGG16", "MobileNetV2", "ViT"]
feature_selector_options = ["None", "Boruta", "SelectKBest"]
dim_reduction_options = ["None", "PCA"]
classifiers = ["Random Forest", "SVM", "Logistic Regression", "k-NN"]

fe_method = st.sidebar.selectbox("Feature Extraction", feature_extractors)
fs_method = st.sidebar.selectbox("Feature Selection", feature_selector_options)
dr_method = st.sidebar.selectbox("Dimensionality Reduction", dim_reduction_options)
clf_method = st.sidebar.selectbox("Classifier", classifiers)

run_button = st.sidebar.button("Run Classification")

# === Helper Functions ===
def extract_dataset(zip_file):
    temp_dir = tempfile.mkdtemp()
    zip_path = os.path.join(temp_dir, "uploaded.zip")
    with open(zip_path, "wb") as f:
        f.write(zip_file.read())
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(temp_dir)
    for folder in os.listdir(temp_dir):
        if os.path.isdir(os.path.join(temp_dir, folder)):
            return os.path.join(temp_dir, folder)
    return temp_dir

def load_data(data_dir):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    dataset = datasets.ImageFolder(data_dir, transform=transform)
    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)
    return loader, dataset.classes

def get_model(name):
    if name == "ResNet-18":
        model = resnet18(pretrained=True)
        return torch.nn.Sequential(*list(model.children())[:-1])
    elif name == "VGG16":
        model = vgg16(pretrained=True)
        return torch.nn.Sequential(*list(model.features))
    elif name == "MobileNetV2":
        model = mobilenet_v2(pretrained=True)
        return model.features
    elif name == "ViT":
        model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')
        return model

def extract_features(model, loader, fe_type):
    model.eval()
    model.to("cpu")
    features, labels = [], []
    processor = ViTImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k") if fe_type == "ViT" else None
    with torch.no_grad():
        for x, y in loader:
            if fe_type == "ViT":
                inputs = processor(images=x[0], return_tensors="pt")
                outputs = model(**inputs)
                feat = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
            else:
                out = model(x)
                feat = out.view(out.size(0), -1).numpy()[0]
            features.append(feat)
            labels.append(y.item())
    return np.array(features), np.array(labels)

def feature_selection(X, y, method):
    if method == "Boruta":
        forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)
        boruta = BorutaPy(estimator=forest, n_estimators='auto', random_state=42)
        boruta.fit(X, y)
        return boruta.transform(X)
    elif method == "SelectKBest":
        selector = SelectKBest(score_func=chi2, k=20)
        return selector.fit_transform(X, y)
    return X

def reduce_dims(X, method):
    if method == "PCA":
        pca = PCA(n_components=0.95)
        return pca.fit_transform(X)
    return X

def classify(X, y, method):
    split = int(0.8 * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]
    if method == "Random Forest":
        clf = RandomForestClassifier()
    elif method == "SVM":
        clf = SVC()
    elif method == "Logistic Regression":
        clf = LogisticRegression(max_iter=1000)
    elif method == "k-NN":
        clf = KNeighborsClassifier()
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    st.subheader("Classification Report")
    st.text(classification_report(y_test, y_pred))
    st.subheader("Confusion Matrix")
    st.text(confusion_matrix(y_test, y_pred))

# === Main Execution ===
if run_button and zip_file:
    st.info("Extracting and processing dataset...")
    data_path = extract_dataset(zip_file)
    loader, class_names = load_data(data_path)

    st.success("Dataset loaded with classes: " + ", ".join(class_names))
    st.info("Extracting features using " + fe_method)
    model = get_model(fe_method)
    X, y = extract_features(model, loader, fe_method)

    X = feature_selection(X, y, fs_method)
    X = reduce_dims(X, dr_method)

    st.success("Starting classification with " + clf_method)
    classify(X, y, clf_method)

    st.balloons()

elif run_button and not zip_file:
    st.error("Please upload a dataset ZIP file.")